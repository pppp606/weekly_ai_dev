## 今週のAI論文トレンド

1. **タイトル:** Kling-Omni Technical Report
   **著者:** Jialu Chen, Yuanzheng Ci, Xiangyu Du, Zipeng Feng, Kun Gai, Sainan Guo, Feng Han, Jingbin He, Kang He, Xiao Hu, Xiaohua Hu, Boyuan Jiang, Fangyuan Kong, Hang Li, Jie Li, Qingyu Li, Shen Li, Xiaohan Li, Yan Li, Jiajun Liang, Borui Liao, Yiqiao Liao, Weihong Lin, Quande Liu, Xiaokun Liu, Yilun Liu, Yuliang Liu, Shun Lu, Hangyu Mao, Yunyao Mao 他（計67名）
   **概要:** Kling-Omniは、マルチモーダル視覚言語入力から高品質な動画を直接生成する汎用生成フレームワークである。本システムの最大の特徴は、動画生成、編集、推論を単一のプラットフォームに統合している点にある。テキスト、画像、動画コンテキストなど多様な入力形式をサポートし、シネマティック品質かつ高度にインテリジェントな動画コンテンツ制作を実現する。大規模な事前学習と包括的なデータシステムを基盤とし、文脈内生成、推論ベースの編集、指示追従において優れた性能を発揮する。本研究は、動的で複雑な世界を知覚・推論・生成・相互作用できるマルチモーダルワールドシミュレータへの重要な一歩を示している。
   **arXiv:** https://arxiv.org/abs/2512.16776

2. **タイトル:** Step-GUI Technical Report
   **著者:** Haolong Yan, Jia Wang, Xin Huang, Yeqing Shen, Ziyang Meng, Zhimin Fan, Kaijun Tan, Jin Gao, Lieyu Shi, Mi Yang, Shiliang Yang, Zhirui Wang, Brian Li, Kang An, Chenyang Li 他（計100名以上）
   **概要:** Step-GUIは、GUI自動化タスクにおけるAIエージェントの訓練効率を大幅に向上させる自己進化パイプラインを提案している。核心となるのは「Calibrated Step Reward System」と呼ばれる報酬システムで、モデルが生成した軌跡を信頼性の高い訓練シグナルに変換する。これにより、従来の10〜100分の1のコストで90%のアノテーション精度を達成した。Step-GUIモデルファミリー（4B/8Bパラメータ）は複数のベンチマークで最先端の性能を示している。さらに、プライバシー保護型自動化をサポートするGUI-MCPプロトコルと、実際のモバイル使用シナリオを反映したAndroidDailyベンチマークも併せて提案されている。
   **arXiv:** https://arxiv.org/abs/2512.15431

3. **タイトル:** MMGR: Multi-Modal Generative Reasoning
   **著者:** Zefan Cai, Haoyi Qiu, Tianyi Ma, Haozhe Zhao, Gengze Zhou, Kung-Hsiang Huang, Parisa Kordjamshidi, Minjia Zhang, Wen Xiao, Jiuxiang Gu, Nanyun Peng, Junjie Hu
   **概要:** MMGRは、動画・画像生成モデルの推論能力を評価するための包括的なフレームワークである。物理的推論、論理的推論、3D空間推論、2D空間推論、時間的推論の5つの次元でモデルを評価する。評価対象は抽象推論（ARC-AGI、数独）、身体化ナビゲーション（3Dナビゲーション・位置特定）、物理的常識（スポーツ・構成的相互作用）の3つのタスクドメインである。Veo-3、Sora-2、Wan-2.2などの主要モデルを検証した結果、物理的常識では中程度の性能を示す一方、抽象推論では10%未満の精度に留まることが判明した。本研究は、知覚データへの過度の依存、大域的状態の一貫性の欠如、因果的正確性より視覚的妥当性を重視する目的関数といった根本的な課題を明らかにしている。
   **arXiv:** https://arxiv.org/abs/2512.14691
