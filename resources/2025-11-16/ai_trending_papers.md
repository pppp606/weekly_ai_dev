## 🧠 今週のAI論文トレンド

1. **タイトル:** Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds
   **著者:** ByteDance Seed
   **概要:** 3Dオープンワールド環境で数時間にわたる複雑なミッションをリアルタイムに完遂できる、初のオープンソース汎用エージェントレシピ「Lumine」を発表。人間のようなインタラクションパラダイムを採用し、視覚言語モデルを用いて知覚・推論・行動をエンドツーエンドで統合しています。原神（Genshin Impact）での学習により、5時間のモンド編メインストーリーを人間レベルの効率で完了し、自然言語指示に従って探索・戦闘・パズル・NPC対話など幅広いタスクを実行可能です。特筆すべきは、ファインチューニングなしで鳴潮（Wuthering Waves）で100分のミッション、崩壊：スターレイルで5時間の第1章をゼロショットで達成したクロスゲーム汎化能力です。5Hzで生のピクセルを処理し、30Hzで精密なキーボード・マウス操作を生成し、必要時のみ推論を適応的に呼び出す効率的な設計により、オープンエンド環境における汎用エージェントへの具体的な一歩を示しています。
   **arXiv:** https://arxiv.org/abs/2511.08892

2. **タイトル:** Grounding Computer Use Agents on Human Demonstrations
   **著者:** ServiceNow
   **概要:** 信頼性の高いコンピュータ使用エージェントの構築には、自然言語指示と画面要素を正確に結びつける「グラウンディング」が不可欠ですが、デスクトップ環境での高品質データセットが不足していました。本研究では、エキスパートによる実演から構築された大規模デスクトップグラウンディングデータセット「GroundCUA」を導入しています。87のアプリケーション（12カテゴリ）、56,000枚のスクリーンショット、356万以上の人間検証済みアノテーションを含み、多様な実世界タスクをカバーしています。このデータセットを用いて開発された「GroundNext」モデル群（3B/7Bスケール）は、従来手法の10分の1未満の学習データで5つのベンチマークにおいて最先端の結果を達成しました。強化学習によるポストトレーニングでさらに性能が向上し、OSWorldベンチマークでo3をプランナーとして使用した場合、はるかに多くのデータで訓練されたモデルと同等以上の結果を示しました。本研究は、汎用コンピュータ使用エージェントの進化において、高品質なエキスパート駆動データセットの重要性を実証しています。
   **arXiv:** https://arxiv.org/abs/2511.07332

3. **タイトル:** Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B
   **著者:** WeiboAI
   **概要:** 小規模モデルには推論能力が不足するという定説に挑戦し、わずか1.5Bパラメータの密なモデル「VibeThinker-1.5B」を開発しました。Spectrum-to-Signal Principle（SSP）に基づき、Two-Stage Diversity-Exploring Distillation（解生成）とMaxEnt-Guided Policy Optimization（方策最適化）を採用した手法により、総訓練コストはわずか7,800ドルで実現されています。このコンパクトなモデルは、Mistral MediumやClaude Opus 4といったクローズドソースモデルに匹敵する推論性能を示し、GPT-OSS-20B Mediumなどのオープンソース代替品とも肩を並べます。数学ベンチマークにおいては、自身の400倍のサイズのモデルを上回る成績を記録：AIME24（80.3 vs 79.8）、AIME25（74.4 vs 70.0）、HMMT25（50.4 vs 41.7）。LiveCodeBench V6では51.1を達成し、Mistral Mediumの50.3を超えました。本研究は、小規模モデルでも大規模モデルと同等の推論能力を実現できることを実証し、計算コストの削減と高度なAI機能へのアクセス拡大への道を開いています。
   **arXiv:** https://arxiv.org/abs/2511.06221
